**[■ 目次](https://github.com/CyberAgentAILab/model-acceleration-tutorial/tree/main?tab=readme-ov-file#table-of-contents)**　**[◀ 前へ](https://github.com/CyberAgentAILab/model-acceleration-tutorial/blob/main/01_Introduction/1_1-Purpose_of_this_tutorial.md)**　**[次へ ▶](https://github.com/CyberAgentAILab/model-acceleration-tutorial/blob/main/02_Runtime/2_1-Runtime_Options.md)**

## 1-2. 解説すること・しないこと (1 min)
モデルのアーキテクチャやアルゴリズムに関しては皆さんはよくご存知である、という前提のもとに、このチュートリアルでは、以下の通り **`解説すること`** と **`解説しないこと`** を明確にし、皆さんが普段あまり触れる機会が少ないと想定されるトピックを特に厳選して説明する想定です。他のチュートリアルとの内容重複はできる限り生じないように説明します。なお、このチュートリアルで不足する技術的な内容や知識は他のチュートリアルと組み合わせて購読することで相互補完的・包括的にノウハウを学べるものと考えます。

### 解説すること
- モデルをデプロイするときのランタイムの選択肢とそれぞれのメリット・デメリット、デプロイ先
- 研究からプロダクト転用を見越したモデル設計時に注意したいこと（以下全てコードレベルでの詳解とする）

### 解説しないこと
- Python以外の言語によるモデル設計手法
- PyTorch以外のフレームワークによるモデル設計（例えば JAX, TensorFlow/Keras）
- モデルのトレーニングの手法
- モデルトレーニングの高速化
- モデルのアーキテクチャ
- オンプレ以外の外部APIを使用した推論の最適化・高速化手法など
- Docker環境構築の内容

では、早速解説していきます。

**[■ 目次](https://github.com/CyberAgentAILab/model-acceleration-tutorial/tree/main?tab=readme-ov-file#table-of-contents)**　**[◀ 前へ](https://github.com/CyberAgentAILab/model-acceleration-tutorial/blob/main/01_Introduction/1_1-Purpose_of_this_tutorial.md)**　**[次へ ▶](https://github.com/CyberAgentAILab/model-acceleration-tutorial/blob/main/02_Runtime/2_1-Runtime_Options.md)**
