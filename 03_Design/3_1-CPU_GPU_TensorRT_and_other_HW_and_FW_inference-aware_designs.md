**[■ 目次](https://github.com/CyberAgentAILab/model-acceleration-tutorial/tree/main?tab=readme-ov-file#table-of-contents)**　**[◀ 前へ](https://github.com/CyberAgentAILab/model-acceleration-tutorial/blob/main/02_Runtime/2_2-Model_Deployment_Destination_Device_and_Runtime_Combination.md)**　**[次へ ▶]()**

## 3-1. CPU・GPU・TensorRT、他HW・FW推論を意識した設計
学習可能なフレームワークで設計したモデルをできる限り汎用的に多くのランタイムへ適合させることを考える場合、多くの細かな点を意識しておく必要が有ります。ココでは大まかなポイントを記載し、次の節以降で実際に手を動かしながら具体的にどのようなことを述べているのかを理解いただきながら進めていきます。

まず、大まかに意識しておいたほうがよいポイントを下記に列記します。


**[■ 目次](https://github.com/CyberAgentAILab/model-acceleration-tutorial/tree/main?tab=readme-ov-file#table-of-contents)**　**[◀ 前へ](https://github.com/CyberAgentAILab/model-acceleration-tutorial/blob/main/02_Runtime/2_2-Model_Deployment_Destination_Device_and_Runtime_Combination.md)**　**[次へ ▶]()**
